# üìä H∆∞·ªõng d·∫´n Tr·ª±c quan h√≥a Qu√° tr√¨nh Training

## T·ªïng quan

Sau khi training, ch∆∞∆°ng tr√¨nh s·∫Ω t·ª± ƒë·ªông xu·∫•t file CSV ch·ª©a l·ªãch s·ª≠ training. B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng script Python `visualize_training.py` ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.

## File CSV ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông

| Phi√™n b·∫£n | File CSV | N·ªôi dung |
|-----------|----------|----------|
| CPU | `training_history_cpu.csv` | epoch, train_loss, test_loss, time_sec, is_best |
| GPU | `training_history_gpu.csv` | epoch, train_loss, test_loss, time_sec, is_best |

## C√†i ƒë·∫∑t th∆∞ vi·ªán Python

```bash
pip install matplotlib pandas numpy
```

## C√°ch s·ª≠ d·ª•ng

### 1. T·ª± ƒë·ªông detect (khuy√™n d√πng)

```bash
python visualize_training.py
```

Script s·∫Ω t·ª± ƒë·ªông:
- N·∫øu ch·ªâ c√≥ CPU CSV ‚Üí v·∫Ω bi·ªÉu ƒë·ªì CPU
- N·∫øu ch·ªâ c√≥ GPU CSV ‚Üí v·∫Ω bi·ªÉu ƒë·ªì GPU  
- N·∫øu c√≥ c·∫£ 2 ‚Üí v·∫Ω bi·ªÉu ƒë·ªì so s√°nh

### 2. Ch·ªâ ƒë·ªãnh mode c·ª• th·ªÉ

```bash
# Ch·ªâ v·∫Ω CPU
python visualize_training.py cpu

# Ch·ªâ v·∫Ω GPU
python visualize_training.py gpu

# So s√°nh CPU vs GPU
python visualize_training.py compare

# File CSV t√πy ch·ªânh
python visualize_training.py path/to/custom.csv
```

## Bi·ªÉu ƒë·ªì ƒë∆∞·ª£c t·∫°o

### Mode ƒë∆°n (CPU ho·∫∑c GPU)

| Bi·ªÉu ƒë·ªì | M√¥ t·∫£ |
|---------|-------|
| **Loss Curve** | Train/Test loss qua t·ª´ng epoch, ƒë√°nh d·∫•u epoch t·ªët nh·∫•t |
| **Time per Epoch** | Th·ªùi gian training m·ªói epoch (bar chart) |

### Mode so s√°nh (Compare)

| Bi·ªÉu ƒë·ªì | M√¥ t·∫£ |
|---------|-------|
| **Loss Comparison** | So s√°nh train/test loss gi·ªØa CPU v√† GPU |
| **Time Comparison** | So s√°nh th·ªùi gian m·ªói epoch |
| **Speedup** | T·ª∑ l·ªá tƒÉng t·ªëc GPU so v·ªõi CPU |
| **Cumulative Time** | T·ªïng th·ªùi gian t√≠ch l≈©y, hi·ªÉn th·ªã th·ªùi gian ti·∫øt ki·ªám |

## Output files

```
training_plot_cpu.png       # Bi·ªÉu ƒë·ªì CPU
training_plot_gpu.png       # Bi·ªÉu ƒë·ªì GPU
training_comparison.png     # Bi·ªÉu ƒë·ªì so s√°nh
```

## S·ª≠ d·ª•ng tr√™n Google Colab

```python
# Cell 1: C√†i th∆∞ vi·ªán
!pip install matplotlib pandas numpy

# Cell 2: Sau khi train xong, v·∫Ω bi·ªÉu ƒë·ªì
!python visualize_training.py

# Cell 3: Hi·ªÉn th·ªã ·∫£nh trong notebook
from IPython.display import Image, display

# Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì (ch·ªçn file ph√π h·ª£p)
display(Image('training_plot_cpu.png'))
# ho·∫∑c
display(Image('training_plot_gpu.png'))
# ho·∫∑c
display(Image('training_comparison.png'))
```

## V√≠ d·ª• Output Console

```
==================================================
SUMMARY - CPU Autoencoder
==================================================
Total Epochs:      10
Final Train Loss:  0.012345
Final Test Loss:   0.015678
Best Test Loss:    0.014567 (Epoch 8)
Total Time:        1234.56 seconds
Average Time:      123.46 seconds/epoch
==================================================
```

## So s√°nh CPU vs GPU (Console Output)

```
============================================================
COMPARISON SUMMARY: CPU vs GPU
============================================================
Metric                            CPU             GPU
------------------------------------------------------------
Final Train Loss               0.012345        0.012389
Final Test Loss                0.015678        0.015701
Best Test Loss                 0.014567        0.014623
Total Time (s)                 1234.56          234.56
Avg Time/Epoch (s)              123.46           23.46
------------------------------------------------------------
Average Speedup                               5.26x
Max Speedup                                   6.12x
Min Speedup                                   4.89x
Time Saved                                 1000.00 seconds
============================================================
```

## L∆∞u √Ω

1. **Ch·∫°y training tr∆∞·ªõc** - File CSV ch·ªâ ƒë∆∞·ª£c t·∫°o sau khi training ho√†n th√†nh
2. **C√πng s·ªë epoch** - ƒê·ªÉ so s√°nh ch√≠nh x√°c, CPU v√† GPU n√™n train c√πng s·ªë epoch
3. **C√πng d·ªØ li·ªáu** - S·ª≠ d·ª•ng c√πng max_samples ƒë·ªÉ so s√°nh c√¥ng b·∫±ng

## V√≠ d·ª• workflow ƒë·∫ßy ƒë·ªß

```bash
# 1. Train CPU version
./autoencoder_cpu ./cifar-10-batches-bin 10 32 0 adam

# 2. Train GPU version (tr√™n m√°y c√≥ CUDA)
./autoencoder_gpu ./cifar-10-batches-bin 10 32 0 adam

# 3. Copy file CSV v·ªÅ c√πng th∆∞ m·ª•c (n·∫øu c·∫ßn)
# 4. V·∫Ω bi·ªÉu ƒë·ªì so s√°nh
python visualize_training.py compare
```

---

# üñºÔ∏è H∆∞·ªõng d·∫´n Tr·ª±c quan h√≥a ·∫¢nh Reconstructed

## T·ªïng quan

Sau khi training, ch∆∞∆°ng tr√¨nh s·∫Ω t·ª± ƒë·ªông export m·ªôt s·ªë ·∫£nh test v√† ·∫£nh reconstructed ra file binary. B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng script Python `visualize_reconstruction.py` ƒë·ªÉ so s√°nh **Original vs Reconstructed**.

## File Binary ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông

| Phi√™n b·∫£n | File Binary | N·ªôi dung |
|-----------|-------------|----------|
| CPU | `reconstructed_images_cpu.bin` | 10 ·∫£nh test (original + reconstructed + labels + MSE) |
| GPU | `reconstructed_images_gpu.bin` | 10 ·∫£nh test (original + reconstructed + labels + MSE) |

## C√†i ƒë·∫∑t th∆∞ vi·ªán Python

```bash
pip install matplotlib numpy
```

## C√°ch s·ª≠ d·ª•ng

### 1. T·ª± ƒë·ªông detect (khuy√™n d√πng)

```bash
python visualize_reconstruction.py
```

Script s·∫Ω t·ª± ƒë·ªông:
- N·∫øu c√≥ CPU file ‚Üí v·∫Ω ·∫£nh CPU reconstruction
- N·∫øu c√≥ GPU file ‚Üí v·∫Ω ·∫£nh GPU reconstruction

### 2. Ch·ªâ ƒë·ªãnh file c·ª• th·ªÉ

```bash
# File CPU
python visualize_reconstruction.py reconstructed_images_cpu.bin

# File GPU  
python visualize_reconstruction.py reconstructed_images_gpu.bin

# File t√πy ch·ªânh
python visualize_reconstruction.py path/to/custom.bin
```

### 3. So s√°nh CPU vs GPU

```bash
python visualize_reconstruction.py --compare
# ho·∫∑c
python visualize_reconstruction.py -c
```

## Bi·ªÉu ƒë·ªì ƒë∆∞·ª£c t·∫°o

### Bi·ªÉu ƒë·ªì ch√≠nh (3 h√†ng)

| H√†ng | N·ªôi dung |
|------|----------|
| **Original** | ·∫¢nh g·ªëc t·ª´ CIFAR-10 test set v·ªõi label |
| **Reconstructed** | ·∫¢nh ƒë∆∞·ª£c t√°i t·∫°o qua Autoencoder v·ªõi MSE |
| **Difference (5x)** | S·ª± kh√°c bi·ªát gi·ªØa 2 ·∫£nh (ph√≥ng ƒë·∫°i 5 l·∫ßn) |

### Bi·ªÉu ƒë·ªì chi ti·∫øt (4 c·ªôt)

| C·ªôt | N·ªôi dung |
|-----|----------|
| **Original** | ·∫¢nh g·ªëc |
| **Reconstructed** | ·∫¢nh reconstructed |
| **Difference (3x)** | S·ª± kh√°c bi·ªát m√†u (ph√≥ng ƒë·∫°i 3 l·∫ßn) |
| **Error Heatmap** | B·∫£n ƒë·ªì nhi·ªát hi·ªÉn th·ªã v√πng c√≥ l·ªói cao |

## Output files

```
reconstruction_cpu.png              # So s√°nh Original vs Reconstructed (CPU)
reconstruction_cpu_detailed.png     # Ph√¢n t√≠ch chi ti·∫øt v·ªõi heatmap (CPU)
reconstruction_gpu.png              # So s√°nh Original vs Reconstructed (GPU)
reconstruction_gpu_detailed.png     # Ph√¢n t√≠ch chi ti·∫øt v·ªõi heatmap (GPU)
reconstruction_comparison.png       # So s√°nh CPU vs GPU reconstruction
```

## S·ª≠ d·ª•ng tr√™n Google Colab

```python
# Cell 1: C√†i th∆∞ vi·ªán
!pip install matplotlib numpy

# Cell 2: Sau khi train xong, v·∫Ω bi·ªÉu ƒë·ªì reconstruction
!python visualize_reconstruction.py

# Cell 3: Hi·ªÉn th·ªã ·∫£nh trong notebook
from IPython.display import Image, display

# Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì reconstruction
display(Image('reconstruction_cpu.png'))
display(Image('reconstruction_cpu_detailed.png'))

# Ho·∫∑c so s√°nh CPU vs GPU
# display(Image('reconstruction_comparison.png'))
```

## V√≠ d·ª• Output Console

```
Loading 10 images (32x32x3)

==================================================
RECONSTRUCTION STATISTICS - CPU Autoencoder
==================================================
Number of samples: 10
Image size: 32x32x3
Mean MSE: 0.012345
Min MSE:  0.008234
Max MSE:  0.018567
Std MSE:  0.003210
==================================================

Plot saved to: reconstruction_cpu.png
Detailed plot saved to: reconstruction_cpu_detailed.png
```

## Gi·∫£i th√≠ch k·∫øt qu·∫£

### MSE (Mean Squared Error)
- **MSE th·∫•p** (< 0.01): Reconstruction r·∫•t t·ªët, ·∫£nh g·∫ßn nh∆∞ gi·ªëng h·ªát
- **MSE trung b√¨nh** (0.01 - 0.05): Reconstruction t·ªët, m·ªôt s·ªë chi ti·∫øt nh·ªè b·ªã m·∫•t
- **MSE cao** (> 0.05): Reconstruction k√©m, nhi·ªÅu th√¥ng tin b·ªã m·∫•t

### Difference Image
- **M√†u ƒëen**: Kh√¥ng c√≥ s·ª± kh√°c bi·ªát
- **M√†u s√°ng**: C√≥ s·ª± kh√°c bi·ªát (c√†ng s√°ng = kh√°c bi·ªát c√†ng l·ªõn)
- Th∆∞·ªùng th·∫•y kh√°c bi·ªát ·ªü c√°c **edge** v√† **chi ti·∫øt nh·ªè**

### Error Heatmap
- **M√†u ƒë·ªè/v√†ng**: V√πng c√≥ l·ªói cao (reconstruction k√©m)
- **M√†u ƒëen/t·ªëi**: V√πng c√≥ l·ªói th·∫•p (reconstruction t·ªët)

## Workflow ƒë·∫ßy ƒë·ªß

```bash
# 1. Train model
./autoencoder_cpu ./cifar-10-batches-bin 5 32 500 adam

# File ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông:
# - training_history_cpu.csv (training history)
# - reconstructed_images_cpu.bin (reconstruction samples)
# - autoencoder_weights.bin (model weights)
# - autoencoder_best.bin (best model weights)

# 2. Visualize training progress
python visualize_training.py

# 3. Visualize reconstruction quality
python visualize_reconstruction.py

# 4. (Optional) So s√°nh CPU vs GPU
# Sau khi c√≥ c·∫£ 2 file reconstruction
python visualize_reconstruction.py --compare
```

## L∆∞u √Ω

1. **Ch·∫°y training tr∆∞·ªõc** - File binary ch·ªâ ƒë∆∞·ª£c t·∫°o sau khi training ho√†n th√†nh
2. **·∫¢nh test** - Script s·ª≠ d·ª•ng 10 ·∫£nh ƒë·∫ßu ti√™n t·ª´ test set
3. **Clip values** - Pixel values ƒë∆∞·ª£c clip v·ªÅ [0, 1] ƒë·ªÉ hi·ªÉn th·ªã ƒë√∫ng
4. **Loss t∆∞∆°ng quan MSE** - MSE c·ªßa t·ª´ng ·∫£nh t∆∞∆°ng quan v·ªõi overall loss
